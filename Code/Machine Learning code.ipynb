{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792cbac2-a55a-47d6-b9c6-54a18aba6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor as XGBR\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "X_train_raw, X_test_raw, Ytrain, Ytest = train_test_split(\n",
    "    x0, y, test_size=0.2, random_state=167\n",
    ")\n",
    "\n",
    "numeric_features = X_train_raw.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train_raw.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='mean')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='__MISSING__')),\n",
    "            ('onehot', OneHotEncoder(\n",
    "                handle_unknown='ignore',\n",
    "                sparse_output=False,\n",
    "                dtype=np.float64\n",
    "            ))  # 绝不标准化独热列！！\n",
    "        ]), categorical_features)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False   # 关键！关闭自动前缀\n",
    ")\n",
    "\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train_raw)\n",
    "X_test_processed = preprocessor.transform(X_test_raw)\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "Xtrain = pd.DataFrame(X_train_processed, columns=feature_names, index=X_train_raw.index)\n",
    "Xtest = pd.DataFrame(X_test_processed, columns=feature_names, index=X_test_raw.index)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# RF\n",
    "def objective_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 200)\n",
    "    max_features = trial.suggest_int('max_features', 1, Xtrain.shape[1])\n",
    "    random_state = trial.suggest_int('random_state', 0, 200)\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    score = cross_val_score(model, Xtrain, Ytrain.ravel(), cv=kf).mean()\n",
    "    return score\n",
    "\n",
    "study_rf = optuna.create_study(direction=\"maximize\")\n",
    "study_rf.optimize(objective_rf, n_trials=150)\n",
    "print(\"RF Best trial:\", study_rf.best_trial.params)\n",
    "\n",
    "# EBM\n",
    "def objective_ebm(trial):\n",
    "    random_state = trial.suggest_int('random_state', 1, 10)\n",
    "    \n",
    "    model = ExplainableBoostingRegressor(random_state=random_state)\n",
    "    score = cross_val_score(model, Xtrain, Ytrain.ravel(), cv=kf).mean()\n",
    "    return score\n",
    "\n",
    "study_ebm = optuna.create_study(direction=\"maximize\")\n",
    "study_ebm.optimize(objective_ebm, n_trials=9)\n",
    "print(\"EBM Best trial:\", study_ebm.best_trial.params)\n",
    "\n",
    "# GDBT\n",
    "def objective_gdbt(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 200)\n",
    "    random_state = trial.suggest_int('random_state', 0, 200)\n",
    "\n",
    "    model = GradientBoostingRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    score = cross_val_score(model, Xtrain, Ytrain.ravel(), cv=kf).mean()\n",
    "    return score\n",
    "\n",
    "study_gdbt = optuna.create_study(direction=\"maximize\")\n",
    "study_gdbt.optimize(objective_gdbt, n_trials=150)\n",
    "print(\"GDBT Best trial:\", study_gdbt.best_trial.params)\n",
    "\n",
    "# XGB\n",
    "def objective_xgb(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 1, 200)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 200)\n",
    "    random_state = trial.suggest_int('random_state', 0, 200)\n",
    "\n",
    "    model = XGBR(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    score = cross_val_score(model, Xtrain, Ytrain.ravel(), cv=kf).mean()\n",
    "    return score\n",
    "\n",
    "study_xgb = optuna.create_study(direction=\"maximize\")\n",
    "study_xgb.optimize(objective_xgb, n_trials=150)\n",
    "print(\"XGB Best trial:\", study_xgb.best_trial.params)\n",
    "\n",
    "# ANN\n",
    "models_ann = []\n",
    "Ytrain_actual, Ytrain_pred = [], []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(Xtrain)):\n",
    "    X_tr, X_va = Xtrain.iloc[train_index], Xtrain.iloc[val_index]\n",
    "    y_tr, y_va = Ytrain.iloc[train_index], Ytrain.iloc[val_index]\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(Xtrain.shape[1],)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    model.fit(X_tr, y_tr, validation_data=(X_va, y_va), epochs=550, batch_size=32, verbose=0, callbacks=[early_stopping])\n",
    "    \n",
    "    y_va_pred = model.predict(X_va).flatten()\n",
    "    Ytrain_actual.extend(y_va.values.flatten())\n",
    "    Ytrain_pred.extend(y_va_pred)\n",
    "    models_ann.append(model)\n",
    "\n",
    "Ytest_preds = [m.predict(Xtest).flatten() for m in models_ann]\n",
    "Ytest_pred_ensemble = np.mean(Ytest_preds, axis=0)\n",
    "print(\"ANN Ensemble Test R2:\", r2_score(Ytest.values.flatten(), Ytest_pred_ensemble))\n",
    "\n",
    "# SVR\n",
    "def objective_svr(trial):\n",
    "    kernel = trial.suggest_categorical('kernel', [\"rbf\", \"poly\", \"sigmoid\"])\n",
    "    C = trial.suggest_float('C', 0.1, 20, log=True)\n",
    "    \n",
    "    n_features = Xtrain.shape[1]\n",
    "    gamma_upper = max(0.01, min(1, 10 / n_features))\n",
    "    gamma = trial.suggest_float('gamma', 1e-5, gamma_upper, log=True)\n",
    "    \n",
    "    degree = trial.suggest_int('degree', 2, 5) if kernel == 'poly' else 3\n",
    "    coef0 = trial.suggest_float('coef0', 0.0, 1.0) if kernel in ['poly', 'sigmoid'] else 0.0\n",
    "    \n",
    "    model = SVR(kernel=kernel, C=C, gamma=gamma, degree=degree, coef0=coef0)\n",
    "    score = cross_val_score(model, Xtrain, Ytrain.ravel(), cv=kf).mean()\n",
    "    return score\n",
    "\n",
    "study_svr = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "study_svr.optimize(objective_svr, n_trials=150)\n",
    "print(\"SVR Best trial:\", study_svr.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
